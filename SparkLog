Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
19/06/07 03:23:56 INFO SparkContext: Running Spark version 2.3.3
19/06/07 03:23:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
19/06/07 03:24:01 INFO SparkContext: Submitted application: SparkSqqopProject1
19/06/07 03:24:02 INFO SecurityManager: Changing view acls to: root
19/06/07 03:24:02 INFO SecurityManager: Changing modify acls to: root
19/06/07 03:24:02 INFO SecurityManager: Changing view acls groups to: 
19/06/07 03:24:02 INFO SecurityManager: Changing modify acls groups to: 
19/06/07 03:24:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
19/06/07 03:24:06 INFO Utils: Successfully started service 'sparkDriver' on port 36902.
19/06/07 03:24:06 INFO SparkEnv: Registering MapOutputTracker
19/06/07 03:24:06 INFO SparkEnv: Registering BlockManagerMaster
19/06/07 03:24:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
19/06/07 03:24:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
19/06/07 03:24:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-911b9289-665c-47c0-915f-3d2649a277b5
19/06/07 03:24:06 INFO MemoryStore: MemoryStore started with capacity 325.8 MB
19/06/07 03:24:07 INFO SparkEnv: Registering OutputCommitCoordinator
19/06/07 03:24:08 INFO Utils: Successfully started service 'SparkUI' on port 4040.
19/06/07 03:24:09 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://master:4040
19/06/07 03:24:11 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://master:7077...
19/06/07 03:24:12 INFO TransportClientFactory: Successfully created connection to master/10.10.10.1:7077 after 339 ms (0 ms spent in bootstraps)
19/06/07 03:24:12 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20190607032412-0001
19/06/07 03:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20190607032412-0001/0 on worker-20190607031409-10.10.10.2-45399 (10.10.10.2:45399) with 2 core(s)
19/06/07 03:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20190607032412-0001/0 on hostPort 10.10.10.2:45399 with 2 core(s), 1024.0 MB RAM
19/06/07 03:24:12 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20190607032412-0001/1 on worker-20190607031354-10.10.10.3-45996 (10.10.10.3:45996) with 2 core(s)
19/06/07 03:24:12 INFO StandaloneSchedulerBackend: Granted executor ID app-20190607032412-0001/1 on hostPort 10.10.10.3:45996 with 2 core(s), 1024.0 MB RAM
19/06/07 03:24:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20190607032412-0001/1 is now RUNNING
19/06/07 03:24:13 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20190607032412-0001/0 is now RUNNING
19/06/07 03:24:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33614.
19/06/07 03:24:13 INFO NettyBlockTransferService: Server created on master:33614
19/06/07 03:24:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
19/06/07 03:24:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, master, 33614, None)
19/06/07 03:24:13 INFO BlockManagerMasterEndpoint: Registering block manager master:33614 with 325.8 MB RAM, BlockManagerId(driver, master, 33614, None)
19/06/07 03:24:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, master, 33614, None)
19/06/07 03:24:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, master, 33614, None)
19/06/07 03:24:15 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
19/06/07 03:24:19 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/root/workspace/Project1ScoopSpark/spark-warehouse').
19/06/07 03:24:19 INFO SharedState: Warehouse path is 'file:/root/workspace/Project1ScoopSpark/spark-warehouse'.
19/06/07 03:24:42 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.10.3:35006) with ID 1
19/06/07 03:24:46 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.10.3:45850 with 366.3 MB RAM, BlockManagerId(1, 10.10.10.3, 45850, None)
19/06/07 03:24:46 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.10.10.2:36978) with ID 0
19/06/07 03:24:46 INFO StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint
19/06/07 03:24:47 INFO BlockManagerMasterEndpoint: Registering block manager 10.10.10.2:42196 with 366.3 MB RAM, BlockManagerId(0, 10.10.10.2, 42196, None)
19/06/07 03:25:52 INFO SparkContext: Starting job: parquet at Spark1.scala:10
19/06/07 03:25:53 INFO DAGScheduler: Got job 0 (parquet at Spark1.scala:10) with 1 output partitions
19/06/07 03:25:53 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at Spark1.scala:10)
19/06/07 03:25:53 INFO DAGScheduler: Parents of final stage: List()
19/06/07 03:25:53 INFO DAGScheduler: Missing parents: List()
19/06/07 03:25:54 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at Spark1.scala:10), which has no missing parents
19/06/07 03:25:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 63.2 KB, free 325.7 MB)
19/06/07 03:25:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.1 KB, free 325.7 MB)
19/06/07 03:25:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on master:33614 (size: 22.1 KB, free: 325.8 MB)
19/06/07 03:25:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1039
19/06/07 03:25:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at Spark1.scala:10) (first 15 tasks are for partitions Vector(0))
19/06/07 03:25:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
19/06/07 03:25:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, 10.10.10.3, executor 1, partition 0, PROCESS_LOCAL, 8043 bytes)
19/06/07 03:26:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.10.10.3:45850 (size: 22.1 KB, free: 366.3 MB)
19/06/07 03:26:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 25219 ms on 10.10.10.3 (executor 1) (1/1)
19/06/07 03:26:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
19/06/07 03:26:24 INFO DAGScheduler: ResultStage 0 (parquet at Spark1.scala:10) finished in 28.572 s
19/06/07 03:26:24 INFO DAGScheduler: Job 0 finished: parquet at Spark1.scala:10, took 32.453392 s
19/06/07 03:26:27 INFO ContextCleaner: Cleaned accumulator 19
19/06/07 03:26:27 INFO ContextCleaner: Cleaned accumulator 15
19/06/07 03:26:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on master:33614 in memory (size: 22.1 KB, free: 325.8 MB)
19/06/07 03:26:29 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.10.10.3:45850 in memory (size: 22.1 KB, free: 366.3 MB)
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 9
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 0
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 24
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 16
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 12
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 11
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 13
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 20
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 21
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 23
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 5
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 2
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 22
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 4
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 10
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 18
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 8
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 14
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 17
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 7
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 3
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 6
19/06/07 03:26:29 INFO ContextCleaner: Cleaned accumulator 1
19/06/07 03:27:31 INFO FileSourceStrategy: Pruning directories with: 
19/06/07 03:27:31 INFO FileSourceStrategy: Post-Scan Filters: 
19/06/07 03:27:31 INFO FileSourceStrategy: Output Data Schema: struct<address_id: int, address: string>
19/06/07 03:27:32 INFO FileSourceScanExec: Pushed Filters: 
19/06/07 03:27:43 INFO CodeGenerator: Code generated in 2554.677196 ms
19/06/07 03:27:46 INFO CodeGenerator: Code generated in 489.240395 ms
19/06/07 03:27:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 223.2 KB, free 325.6 MB)
19/06/07 03:27:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 21.1 KB, free 325.6 MB)
19/06/07 03:27:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on master:33614 (size: 21.1 KB, free: 325.8 MB)
19/06/07 03:27:47 INFO SparkContext: Created broadcast 1 from show at Spark1.scala:13
19/06/07 03:27:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
19/06/07 03:27:49 INFO SparkContext: Starting job: show at Spark1.scala:13
19/06/07 03:27:49 INFO DAGScheduler: Got job 1 (show at Spark1.scala:13) with 1 output partitions
19/06/07 03:27:49 INFO DAGScheduler: Final stage: ResultStage 1 (show at Spark1.scala:13)
19/06/07 03:27:49 INFO DAGScheduler: Parents of final stage: List()
19/06/07 03:27:49 INFO DAGScheduler: Missing parents: List()
19/06/07 03:27:49 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[5] at show at Spark1.scala:13), which has no missing parents
19/06/07 03:27:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 10.5 KB, free 325.6 MB)
19/06/07 03:27:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.8 KB, free 325.5 MB)
19/06/07 03:27:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on master:33614 (size: 4.8 KB, free: 325.8 MB)
19/06/07 03:27:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1039
19/06/07 03:27:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at show at Spark1.scala:13) (first 15 tasks are for partitions Vector(0))
19/06/07 03:27:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
19/06/07 03:27:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, 10.10.10.3, executor 1, partition 0, ANY, 8354 bytes)
19/06/07 03:27:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.10.10.3:45850 (size: 4.8 KB, free: 366.3 MB)
19/06/07 03:28:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.10.10.3:45850 (size: 21.1 KB, free: 366.3 MB)
19/06/07 03:28:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 36841 ms on 10.10.10.3 (executor 1) (1/1)
19/06/07 03:28:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
19/06/07 03:28:26 INFO DAGScheduler: ResultStage 1 (show at Spark1.scala:13) finished in 37.204 s
19/06/07 03:28:26 INFO DAGScheduler: Job 1 finished: show at Spark1.scala:13, took 37.519053 s
+----------+-----------------+
|address_id|          address|
+----------+-----------------+
|         1|47 MySakila Drive|
+----------+-----------------+

19/06/07 03:28:28 INFO SparkContext: Invoking stop() from shutdown hook
19/06/07 03:28:29 INFO SparkUI: Stopped Spark web UI at http://master:4040
19/06/07 03:28:30 INFO StandaloneSchedulerBackend: Shutting down all executors
19/06/07 03:28:30 INFO CoarseGrainedSchedulerBackend$DriverEndpoint: Asking each executor to shut down
19/06/07 03:28:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
19/06/07 03:28:34 INFO MemoryStore: MemoryStore cleared
19/06/07 03:28:34 INFO BlockManager: BlockManager stopped
19/06/07 03:28:34 INFO BlockManagerMaster: BlockManagerMaster stopped
19/06/07 03:28:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
19/06/07 03:28:34 INFO SparkContext: Successfully stopped SparkContext
19/06/07 03:28:34 INFO ShutdownHookManager: Shutdown hook called
19/06/07 03:28:35 INFO ShutdownHookManager: Deleting directory /tmp/spark-51f3c3f2-ad60-4e1c-8e80-b791eba79e57


*************************
10.10.10.2 logs
2019-06-07 03:24:16 INFO  CoarseGrainedExecutorBackend:2612 - Started daemon with process name: 21878@slave1
2019-06-07 03:24:16 INFO  SignalUtils:54 - Registered signal handler for TERM
2019-06-07 03:24:16 INFO  SignalUtils:54 - Registered signal handler for HUP
2019-06-07 03:24:16 INFO  SignalUtils:54 - Registered signal handler for INT
2019-06-07 03:24:20 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-07 03:24:20 INFO  SecurityManager:54 - Changing view acls to: root
2019-06-07 03:24:20 INFO  SecurityManager:54 - Changing modify acls to: root
2019-06-07 03:24:20 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-06-07 03:24:20 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-06-07 03:24:20 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2019-06-07 03:24:23 INFO  TransportClientFactory:267 - Successfully created connection to master/10.10.10.1:36902 after 474 ms (0 ms spent in bootstraps)
2019-06-07 03:24:24 INFO  SecurityManager:54 - Changing view acls to: root
2019-06-07 03:24:24 INFO  SecurityManager:54 - Changing modify acls to: root
2019-06-07 03:24:24 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-06-07 03:24:24 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-06-07 03:24:24 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2019-06-07 03:24:25 INFO  TransportClientFactory:267 - Successfully created connection to master/10.10.10.1:36902 after 15 ms (0 ms spent in bootstraps)
2019-06-07 03:24:25 INFO  DiskBlockManager:54 - Created local directory at /tmp/spark-63134ff7-24de-40ec-bd91-c78d0c02a49d/executor-94d2b5e2-c58a-42a0-b0d1-a468270d52c6/blockmgr-ed1edca2-b388-4347-bf99-625b06ca13a7
2019-06-07 03:24:25 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-06-07 03:24:33 INFO  WorkerWatcher:54 - Connecting to worker spark://Worker@10.10.10.2:45399
2019-06-07 03:24:33 INFO  CoarseGrainedExecutorBackend:54 - Connecting to driver: spark://CoarseGrainedScheduler@master:36902
2019-06-07 03:24:33 INFO  TransportClientFactory:267 - Successfully created connection to /10.10.10.2:45399 after 30 ms (0 ms spent in bootstraps)
2019-06-07 03:24:33 INFO  WorkerWatcher:54 - Successfully connected to spark://Worker@10.10.10.2:45399
2019-06-07 03:24:46 INFO  CoarseGrainedExecutorBackend:54 - Successfully registered with driver
2019-06-07 03:24:46 INFO  Executor:54 - Starting executor ID 0 on host 10.10.10.2
2019-06-07 03:24:46 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42196.
2019-06-07 03:24:46 INFO  NettyBlockTransferService:54 - Server created on 10.10.10.2:42196
2019-06-07 03:24:46 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-06-07 03:24:47 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(0, 10.10.10.2, 42196, None)
2019-06-07 03:24:47 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(0, 10.10.10.2, 42196, None)
2019-06-07 03:24:47 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(0, 10.10.10.2, 42196, None)
2019-06-07 03:28:30 INFO  CoarseGrainedExecutorBackend:54 - Driver commanded a shutdown
2019-06-07 03:28:31 ERROR CoarseGrainedExecutorBackend:43 - RECEIVED SIGNAL TERM
utdown
